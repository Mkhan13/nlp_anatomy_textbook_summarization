import streamlit as st
import torch
from transformers import BertTokenizer, BertForSequenceClassification

MODEL_PATH = './models/bert_model'
TOKENIZER_PATH = './models/bert_tokenizer'

label_map = {
    0: "Stress",
    1: "Depression",
    2: "Bipolar disorder",
    3: "Personality disorder",
    4: "Anxiety"
}

@st.cache_resource  # Cache the model so it isnâ€™t reloaded on every interaction

def load_model():
    tokenizer = BertTokenizer.from_pretrained(TOKENIZER_PATH)
    model = BertForSequenceClassification.from_pretrained(MODEL_PATH)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Set device
    model.to(device) 
    model.eval()

    return tokenizer, model, device

tokenizer, model, device = load_model()

def run_frontend():
    st.title("Mental Health Text Sentiment Classifier")
    st.write("Enter a text post to predict the mental health distress category")

    user_input = st.text_area("Enter text here:")

    if st.button("Predict"):
        if user_input.strip() == "":
            st.warning("Please enter some text!")
        else:
            inputs = tokenizer(user_input, truncation=True, padding='max_length', max_length=128, return_tensors='pt') # Tokenize input
            inputs = {k: v.to(device) for k, v in inputs.items()} # Generated by ChatGPT on 10/30/2025, keep input tensors on the same device as model

            with torch.no_grad():
                outputs = model(**inputs) # Get model outputs
                pred = torch.argmax(outputs.logits, dim=1).item() # Get predicted class

            st.success(f"Predicted Category: {label_map.get(pred, 'Unknown')}")